{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93b987df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "104eb97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Machine learning is a field of artificial intelligence where computers learn patterns from data to m...\n",
      "Full answer:\n",
      "Machine learning is a field of artificial intelligence where computers learn patterns from data to make predictions or decisions without being explicitly programmed.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "def langchain_approach():\n",
    "    \"\"\"Langchain - clean and simple\"\"\"\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "        base_url=os.getenv(\"OPENAI_API_BASE\")\n",
    "    )\n",
    "\n",
    "    response = llm.invoke(\"Explain machine learning in one sentence\")\n",
    "\n",
    "    if response:\n",
    "        print(f\"Response: {response.content[:100]}...\")\n",
    "        return response.content \n",
    "    return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    answer = langchain_approach()\n",
    "    if answer:\n",
    "        print(\"Full answer:\")\n",
    "        print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "730c7a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing template with AI\n",
      "==================================================\n",
      "Sending to AI: Explain artificial intelligence in exactly 5 words\n",
      "\n",
      "AI response: Machines simulating human-like intelligence.\n"
     ]
    }
   ],
   "source": [
    "template = PromptTemplate(\n",
    "    input_variables=[\"topic\", \"style\"],\n",
    "    template=\"Explain {topic} in {style}\"\n",
    ")\n",
    "\n",
    "print(\"\\nTesting template with AI\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "llm_prompt = ChatOpenAI(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "        base_url=os.getenv(\"OPENAI_API_BASE\"),\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "if template and llm_prompt:\n",
    "    test_prompt = template.format(\n",
    "        topic = \"artificial intelligence\",\n",
    "        style = \"exactly 5 words\"\n",
    "    )\n",
    "\n",
    "print(f\"Sending to AI: {test_prompt}\")\n",
    "\n",
    "response = llm_prompt.invoke(test_prompt)\n",
    "print(f\"\\nAI response: {response.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ece24648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: List 3 benefits of cloud computing\n",
      "Parsed Output: ['Scalability', 'cost-efficiency', 'accessibility']\n",
      "Type: <class 'list'> - It's a Python list\n",
      "Access items: result[0] = 'Scalability\n"
     ]
    }
   ],
   "source": [
    "llm_output = ChatOpenAI(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "        base_url=os.getenv(\"OPENAI_API_BASE\"),\n",
    "        temperature=0\n",
    "    )\n",
    "list_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "list_prompt = PromptTemplate(\n",
    "    template=\"List 3 benefits of {technology} (comma-separated):\",\n",
    "    input_variables=[\"technology\"]\n",
    ")\n",
    "\n",
    "list_chain = list_prompt | llm_output | list_parser\n",
    "\n",
    "if list_chain:\n",
    "    result = list_chain.invoke({\n",
    "        \"technology\": \"cloud computing\"\n",
    "    })\n",
    "\n",
    "    print(f\"Input: List 3 benefits of cloud computing\")\n",
    "    print(f\"Parsed Output: {result}\")\n",
    "    print(f\"Type: {type(result)} - It's a Python list\")\n",
    "    print(f\"Access items: result[0] = '{result[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ea800da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Analyzing machine learning\n",
      " Parsed Json output:\n",
      " Benefits: ['Ability to automatically learn and improve from data without explicit programming', 'Can handle and analyze large and complex datasets to uncover patterns and insights']\n",
      " Complexity: high\n",
      " Use case: Predictive analytics for customer behavior\n",
      " Type: <class 'dict'> - It's a Python Dict\n",
      "\n",
      " Parser Magic:\n",
      " List Parser: Text -> Python list\n",
      " JSON parser: -> Python Dict\n",
      " Direct data access: result_1[0], parsed['benefits]\n"
     ]
    }
   ],
   "source": [
    "llm_json = ChatOpenAI(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "        base_url=os.getenv(\"OPENAI_API_BASE\"),\n",
    "        temperature=0\n",
    "    )\n",
    "json_parser = JsonOutputParser()\n",
    "\n",
    "json_prompt = PromptTemplate(\n",
    "    template=\"\"\"Analyze {technology} and respond with JSON containing:\n",
    "    - benefits: array of 2 benefits\n",
    "    - complexity: low/medium/high\n",
    "    - use_case: one main use case\n",
    "\n",
    "    Technology : {technology}\n",
    "\n",
    "    {format_instructions}\"\"\",\n",
    "    input_variables=[\"technology\"],\n",
    "    partial_variables={\"format_instructions\": json_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "json_chain = json_prompt | llm_json | json_parser\n",
    "\n",
    "if json_chain:\n",
    "    result_1 = json_chain.invoke({\n",
    "        \"technology\": \"machine learning\"\n",
    "    })\n",
    "\n",
    "    print(f\"Input: Analyzing machine learning\")\n",
    "\n",
    "    try:\n",
    "        parsed = result_1\n",
    "        print(\" Parsed Json output:\")\n",
    "        print(f\" Benefits: {parsed.get('benefits',[])}\")\n",
    "        print(f\" Complexity: {parsed.get('complexity', 'N/A')}\")\n",
    "        print(f\" Use case: {parsed.get('use_case', 'N/A')}\")\n",
    "        print(f\" Type: {type(parsed)} - It's a Python Dict\")\n",
    "    except (json.JSONDecodeError, TypeError, AttributeError):\n",
    "        print(f\"Parsing failed (rare with Jsonoutputparser): {result}\")\n",
    "        \n",
    "print(\"\\n Parser Magic:\")\n",
    "print(\" List Parser: Text -> Python list\")\n",
    "print(\" JSON parser: -> Python Dict\")\n",
    "print(\" Direct data access: result_1[0], parsed['benefits]\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "810390df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Analyze Blockchain\n",
      "Output: ['Scalability', 'cost-efficiency', 'accessibility']\n"
     ]
    }
   ],
   "source": [
    "llm_ana = ChatOpenAI(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "        base_url=os.getenv(\"OPENAI_API_BASE\"),\n",
    "        temperature=0.3\n",
    "    )\n",
    "\n",
    "analysis_prompt = PromptTemplate(\n",
    "    template=\"Analyze {technology} and provide pros and cons in 2-3 sentences\",\n",
    "    input_variables=[\"technology\"]\n",
    ")\n",
    "\n",
    "str_parser = StrOutputParser()\n",
    "\n",
    "analysis_chain = analysis_prompt | llm_ana | str_parser\n",
    "\n",
    "if analysis_chain:\n",
    "    result_2 = analysis_chain.invoke({\n",
    "        \"technology\": \"blockchain\"\n",
    "    })\n",
    "    print(f\"Input: Analyze Blockchain\")\n",
    "    print(f\"Output: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b3c6919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Input: 'List use cases for blockchain'\n",
      "Output: ['Scalability', 'cost-efficiency', 'accessibility']\n",
      "Technology: artificial intelligence\n",
      "\n",
      " Anlysis:\n",
      " Artificial intelligence (AI) enhances efficiency and decision-making by automating complex tasks and analyzing vast data sets, driving innovation across industries. However, it also raises concerns about job displacement, ethical dilemmas, and potential biases embedded in algorithms. Balancing AI's benefits with responsible development is crucial for maximizing its positive impact.\n",
      "\n",
      "Use cases: \n",
      "    1. image recognition\n",
      "    2. natural language processing\n",
      "    3. predictive analytics\n"
     ]
    }
   ],
   "source": [
    "generator_prompt = PromptTemplate(\n",
    "    template=\"List 3 use cases for {technology} (comma-separated):\",\n",
    "    input_variables=[\"technology\"]\n",
    ")\n",
    "\n",
    "generator_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "genrator_chain = generator_prompt | llm_ana | generator_parser\n",
    "\n",
    "if genrator_chain:\n",
    "    result_3 = genrator_chain.invoke({\n",
    "        \"technology\": \"blockchain\"\n",
    "    })\n",
    "    print(f\" Input: 'List use cases for blockchain'\")\n",
    "    print(f\"Output: {result}\")\n",
    "\n",
    "test_tech = \"artificial intelligence\"\n",
    "print(f\"Technology: {test_tech}\\n\")\n",
    "\n",
    "if analysis_chain and genrator_chain:\n",
    "    analysis = analysis_chain.invoke({\"technology\": test_tech})\n",
    "    print(f\" Anlysis:\\n {analysis}\")\n",
    "\n",
    "    use_cases = genrator_chain.invoke({\"technology\": test_tech})\n",
    "    print(f\"\\nUse cases: \")\n",
    "    for i, use_case in enumerate(use_cases,1):\n",
    "        print(f\"    {i}. {use_case}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb45cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
