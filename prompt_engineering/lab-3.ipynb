{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03df71fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate, FewShotPromptTemplate\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db94502",
   "metadata": {},
   "source": [
    "#### Zero Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4aae0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero Shot Prompting Demo\n",
      "==================================================\n",
      "\n",
      "Vague Prompt:\n",
      "Write a data privacy policy\n",
      "\n",
      "Vague Response Preview:\n",
      "**Data Privacy Policy**\n",
      "\n",
      "**Effective Date:** [Insert Date]\n",
      "\n",
      "**1. Introduction**  \n",
      "[Your Company Name] (“we,” “us,” or “our”) is committed to protectin...\n",
      "\n",
      "==================================================\n",
      "\n",
      "Specific Prompt:\n",
      "Write a 200-word data privacy policy for European customers covering GDPR requirements, data retention periods of 30 days, and user rights for deletion and portability.\n",
      "\n",
      "Specific Response Preview:\n",
      "**Data Privacy Policy**\n",
      "\n",
      "We are committed to protecting the privacy and personal data of our European customers in accordance with the General Data Protection Regulation (GDPR). This policy outlines h...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "def generate_privacy_policies():\n",
    "\t\"\"\"\n",
    "\tGenerates two privacy policies:\n",
    "\t1. A vague zero-shot version\n",
    "\t2. A specific zero-shot version\n",
    "\tReturns both responses as a dictionary.\n",
    "\t\"\"\"\n",
    "\n",
    "\tllm = ChatOpenAI(\n",
    "\t\tmodel=\"gpt-4.1-mini\",\n",
    "\t\tapi_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "\t\tbase_url=os.getenv(\"OPENAI_API_BASE\"),\n",
    "\t\ttemperature=0.7\n",
    "\t)\n",
    "\n",
    "\t# ---- Vague Prompt ----\n",
    "\tvague_prompt = \"Write a data privacy policy\"\n",
    "\tvague_response = llm.invoke(vague_prompt)\n",
    "\n",
    "\t# ---- Specific Prompt ----\n",
    "\tspecific_prompt = (\n",
    "\t\t\"Write a 200-word data privacy policy for European customers \"\n",
    "\t\t\"covering GDPR requirements, data retention periods of 30 days, \"\n",
    "\t\t\"and user rights for deletion and portability.\"\n",
    "\t)\n",
    "\tspecific_response = llm.invoke(specific_prompt)\n",
    "\n",
    "\treturn {\n",
    "\t\t\"vague_prompt\": vague_prompt,\n",
    "\t\t\"vague_response\": vague_response.content,\n",
    "\t\t\"specific_prompt\": specific_prompt,\n",
    "\t\t\"specific_response\": specific_response.content\n",
    "\t}\n",
    "\n",
    "\n",
    "def main():\n",
    "\tprint(\"Zero Shot Prompting Demo\")\n",
    "\tprint(\"=\" * 50)\n",
    "\n",
    "\ttry:\n",
    "\t\tresults = generate_privacy_policies()\n",
    "\n",
    "\t\tprint(f\"\\nVague Prompt:\\n{results['vague_prompt']}\")\n",
    "\t\tprint(f\"\\nVague Response Preview:\\n{results['vague_response'][:150]}...\\n\")\n",
    "\n",
    "\t\tprint(\"=\" * 50)\n",
    "\n",
    "\t\tprint(f\"\\nSpecific Prompt:\\n{results['specific_prompt']}\")\n",
    "\t\tprint(f\"\\nSpecific Response Preview:\\n{results['specific_response'][:200]}...\\n\")\n",
    "\n",
    "\t\treturn results\n",
    "\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"Error occurred: {e}\")\n",
    "\t\treturn None\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tmain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35b19db",
   "metadata": {},
   "source": [
    "#### One-Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3088b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating One-Shot template with example\n",
      "========================================\n",
      "REFUND POLICY \n",
      "1. Eligibility: Within 30 days of purchase\n",
      "2. Conditions: Product unused and in original packaging\n",
      "3. Submit request via support@company.com\n",
      "4. Timeline: Refund processed within 5-7 business days\n",
      "5. Exceptions: Digital products and custom orders non-refundable\n",
      "Format need adjustment - check out example\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating One-Shot template with example\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "\t\tmodel=\"gpt-4.1-mini\",\n",
    "\t\tapi_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "\t\tbase_url=os.getenv(\"OPENAI_API_BASE\"),\n",
    "\t\ttemperature=0.7\n",
    "\t)\n",
    "\n",
    "example_policy = \"\"\"REFUND POLICY \\n1. Eligibility: Within 30 days of purchase\\n2. Conditions: Product unused and in original packaging\\n3. Submit request via support@company.com\\n4. Timeline: Refund processed within 5-7 business days\\n5. Exceptions: Digital products and custom orders non-refundable\"\"\"\n",
    "\n",
    "print(example_policy)\n",
    "\n",
    "one_shot_template = PromptTemplate(\n",
    "\ttemplate=\"\"\"Here's an example of our policy format:\n",
    "{example}\n",
    "Now write a {policy_type} policy following this EXACT format with number section:\"\"\",\n",
    "\tinput_variables=[\"example\", \"policy_type\"]\n",
    ")\n",
    "\n",
    "formatted_prompt = one_shot_template.format(\n",
    "\texample = example_policy,\n",
    "\tpolicy_type=\"remote work\"\n",
    ")\n",
    "\n",
    "response = llm.invoke(formatted_prompt)\n",
    "\n",
    "has_numbered_sections = any(f\"{i}. \" in response.content for i in range(1,6))\n",
    "has_consistent_structure = all(\n",
    "\tkeyword in response.content.lower()\n",
    "\tfor keyword in [\"eligibility\", \"conditions\", \"process\", \"timeline\"]\n",
    ")\n",
    "\n",
    "if has_numbered_sections and has_consistent_structure:\n",
    "\tprint(\"Follow exact format of the example\")\n",
    "else:\n",
    "\tprint(\"Format need adjustment - check out example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fcb7f4",
   "metadata": {},
   "source": [
    "#### Few-Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d848a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Few-Shot examples\n",
      "==================================================\n",
      "Example loaded\n",
      "\tExample 1: refund request -> I understnd you'd like a refund. Let me check the ....\n",
      "\tExample 2: shipping delay -> I apologize for the shipping delay. Let me track y....\n",
      "\tExample 3: password reset -> I'll help you reset your password. For security, I....\n",
      "AI response: I see your account is locked. For security reasons, I've sent a verification code to your registered email. Please enter the code to unlock your account. If you need further assistance, I'm here to help.\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating Few-Shot examples\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "\t\tmodel=\"gpt-4.1-mini\",\n",
    "\t\tapi_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "\t\tbase_url=os.getenv(\"OPENAI_API_BASE\"),\n",
    "\t\ttemperature=0.7\n",
    "\t)\n",
    "\n",
    "examples = [\n",
    "\t{\n",
    "\t\t\"input\": \"refund request\",\n",
    "\t\t\"output\": \"I understnd you'd like a refund. Let me check the order details. Our refund policy allows returns within 30 days. I'll process this for you right away.\"\n",
    "\t},\n",
    "\t\n",
    "\t{\n",
    "\t\t\"input\": \"shipping delay\",\n",
    "\t\t\"output\": \"I apologize for the shipping delay. Let me track your package immediately. I see it's currently in transit and should arrive within 2 days. I'll apply a shipping credit to your account\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"input\": \"password reset\",\n",
    "\t\t\"output\": \"I'll help you reset your password. For security, I've sent a reset link to your registered email. The link expires in 1 hour. Please check your spam folder if you don't see it.\"\n",
    "\t}\n",
    "]\n",
    "\n",
    "print(\"Example loaded\")\n",
    "for i, ex in enumerate(examples, 1):\n",
    "\tprint(f\"\tExample {i}: {ex['input']} -> {ex['output'][:50]}....\")\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "\ttemplate=\"Customer Issuse: {input}\\nSupport Response: {output}\",\n",
    "\tinput_variables=[\"input\", \"output\"]\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "\texamples=examples,\n",
    "\texample_prompt=example_prompt,\n",
    "\tprefix=\"You are a helpful customer support agent. Here are examples of how to respond:\",\n",
    "\tsuffix=\"Customer Issue: {input}\\nSupport Response:\",\n",
    "\tinput_variables=[\"input\"]\n",
    "\t\t\n",
    ")\n",
    "\n",
    "test_input = \"account locked\"\n",
    "\n",
    "formatted_prompt = few_shot_prompt.format(input=test_input)\n",
    "\n",
    "response_1 = llm.invoke(formatted_prompt)\n",
    "print(f\"AI response: {response_1.content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f12d1d5",
   "metadata": {},
   "source": [
    "#### Chain-of-Thought Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "baa1b6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain of Thought prompting\n",
      "========================================\n",
      "Part 1: Direct prompt without chain of thought\n",
      "----------------------------------------\n",
      "Part 2: Chain-of-Thought Prompt\n",
      "----------------------------------------\n",
      "Step 1: Review GDRP requirements related to data retention and storage limitation\n",
      "Step 2: Identify compliance gaps in the current data retention policy\n",
      "Step 3: Reference industry best practices for data retention and deletion\n",
      "Step 4: Draft specific, GDPR-compliant policy changes\n",
      "Step 5: Propose an implementation and enforcement timeline\n",
      "Applying chain of though reasoning\n",
      "----------------------------------------\n",
      "\n",
      " Chain-of-thought response: \n",
      "Certainly! Let’s work through each step systematically to fix your data retention policy to comply with GDPR.\n",
      "\n",
      "---\n",
      "\n",
      "### Step 1: Review GDPR Requirements Related to Data Retention and Storage Limitation\n",
      "\n",
      "**Key GDPR principles related to data retention:**\n",
      "\n",
      "- **Purpose limitation (Article 5(1)(b))**: Personal data must be collected for specified, explicit, and legitimate purposes and not further processed in a manner incompatible with those purposes.\n",
      "- **Storage limitation (Article 5(1)(e))**: Pers...\n"
     ]
    }
   ],
   "source": [
    "from sympy import cot\n",
    "\n",
    "\n",
    "print(\"Chain of Thought prompting\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "\t\tmodel=\"gpt-4.1-mini\",\n",
    "\t\tapi_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "\t\tbase_url=os.getenv(\"OPENAI_API_BASE\"),\n",
    "\t\ttemperature=0.7\n",
    ")\n",
    "\n",
    "print(\"Part 1: Direct prompt without chain of thought\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "direct_prompt = \"Our current data retention policy states:\\n- Customer data is stored indefitely\\n- There is no documented data deletion or review process\\n- System backups are retained forever and include personal data\\n- No distinction made between active and inactive users\\n- Fix this policy to comply with GDPR\"\n",
    "\n",
    "direct_response = llm.invoke(direct_prompt)\n",
    "\n",
    "print(\"Part 2: Chain-of-Thought Prompt\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "reasoning_steps = \"\"\"Step 1: Review GDRP requirements related to data retention and storage limitation\\nStep 2: Identify compliance gaps in the current data retention policy\\nStep 3: Reference industry best practices for data retention and deletion\\nStep 4: Draft specific, GDPR-compliant policy changes\\nStep 5: Propose an implementation and enforcement timeline\"\"\"\n",
    "\n",
    "print(reasoning_steps)\n",
    "\n",
    "cot_template = PromptTemplate(\n",
    "    template=\"\"\"To solve this problem, think through it step-by-step:\n",
    "{steps}\n",
    "Problem: {problem}\n",
    "Now, let's work through each step systematically\"\"\",\n",
    "    input_variables=[\"steps\", \"problem\"]   \n",
    ")\n",
    "\n",
    "cot_prompt = cot_template.format(\n",
    "        steps=reasoning_steps,\n",
    "        problem=\"Fix our data retention policy to comply with GDPR\"\n",
    "    )\n",
    "\n",
    "print(\"Applying chain of though reasoning\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "cot_response = llm.invoke(cot_prompt)\n",
    "print(f\"\\n Chain-of-thought response: \\n{cot_response.content[:500]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd70a31",
   "metadata": {},
   "source": [
    "#### Prompting technique comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4e6bbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesing 4 prompting techniques...\n",
      "\n",
      "Zero Shot Prompting\n",
      "----------------------------------------\n",
      "Preview: Creating an effective employee remote work policy is essential for setting clear expectations, maint...\n",
      "One Shot Prompting\n",
      "----------------------------------------\n",
      "Review: REMOTE WORK POLICY\n",
      "\n",
      "1. Eligibility: All full-time employees who have completed their probationary pe...\n",
      "Few Shot prompting\n",
      "----------------------------------------\n",
      "Preview: Policy: Creating an employee remote work policy  \n",
      "Format:  \n",
      "1. Eligibility: Employees must have comp...\n",
      "\n",
      "Chain of Thoughts\n",
      "----------------------------------------\n",
      "Preview: Certainly! Let's work through each step systematically to create a comprehensive employee remote wor...\n",
      "\n",
      "Techniques comparison\n",
      "----------------------------------------\n",
      "\n",
      "ZERO_SHOT: \n",
      " Length: 4793 characters\n",
      " Has Structured: True\n",
      " Specificity: True\n",
      "\n",
      "SINGLE_SHOT: \n",
      " Length: 1228 characters\n",
      " Has Structured: True\n",
      " Specificity: True\n",
      "\n",
      "FEW_SHOT: \n",
      " Length: 635 characters\n",
      " Has Structured: True\n",
      " Specificity: True\n",
      "\n",
      "CHAIN-OF-THOUGHTS: \n",
      " Length: 5842 characters\n",
      " Has Structured: True\n",
      " Specificity: True\n",
      "\n",
      " Most Detailed: chain-of-thoughts (5842 characters)\n"
     ]
    }
   ],
   "source": [
    "from email import policy\n",
    "from unittest import result\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "\t\tmodel=\"gpt-4.1-mini\",\n",
    "\t\tapi_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "\t\tbase_url=os.getenv(\"OPENAI_API_BASE\"),\n",
    "\t\ttemperature=0.7\n",
    "\t)\n",
    "test_problem = \"Creating an employee remote work policy\"\n",
    "\n",
    "print(\"Tesing 4 prompting techniques...\\n\")\n",
    "results = {}\n",
    "\n",
    "# 1. ZERO-SHOT prompting\n",
    "print(\"Zero Shot Prompting\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "zero_shot_result = llm.invoke(test_problem)\n",
    "results['zero_shot'] = zero_shot_result.content\n",
    "print(f\"Preview: {zero_shot_result.content[:100]}...\")\n",
    "\n",
    "# 2. ONE-SHOT PROMPTING\n",
    "print(\"One Shot Prompting\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "single_shot_template = PromptTemplate(\n",
    "    template=\"\"\"Example Policy:\n",
    "VACATION POLICY\n",
    "1. Eligibility: All full-time employeers\n",
    "2. Accrual: 15 days per year\n",
    "3. Request: Submit 2 weeks in advance\n",
    "4. Approval: Manger discretion\n",
    "    \n",
    "Now create: {policy_type}\"\"\",\n",
    "\tinput_variables=[\"policy_type\"]\n",
    ")\n",
    "\n",
    "single_shot_prompt = single_shot_template.format(\n",
    "\tpolicy_type=test_problem\n",
    ")\n",
    "\n",
    "single_shot_result = llm.invoke(single_shot_prompt)\n",
    "results[\"single_shot\"] = single_shot_result.content\n",
    "print(f\"Review: {single_shot_result.content[:100]}...\")\n",
    "\n",
    "# 3. FEW-SHOT Prompting\n",
    "print(\"Few Shot prompting\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "examples = [\n",
    "        {\"policy\": \"sick leave\", \"format\": \"1. Coverage: 10 days/year\\n2. Documentation: Doctor's note after 3 days\"},\n",
    "        {\"policy\": \"training\", \"format\": \"1. Budget: $2000/employee/year\\n2. Approval: Required for external courses\"},\n",
    "    ]\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "\ttemplate=\"Policy: {policy}\\nFormat:\\n{format}\",\n",
    "\tinput_variables=[\"policy\", \"format\"]\n",
    ")\n",
    "\n",
    "shots_template = FewShotPromptTemplate(\n",
    "\texamples=examples,\n",
    "\texample_prompt=example_prompt,\n",
    "\tprefix=\"Examples of our policy format:\",\n",
    "\tsuffix=\"Now create: {policy_type}\",\n",
    "\tinput_variables=[\"policy_type\"]\n",
    ")\n",
    "\n",
    "formatted_shots_template = shots_template.format(\n",
    "\tpolicy_type=test_problem\n",
    ")\n",
    "\n",
    "shots_result = llm.invoke(formatted_shots_template)\n",
    "results[\"few_shot\"] = shots_result.content\n",
    "print(f\"Preview: {shots_result.content[:100]}...\\n\")\n",
    "\n",
    "# 4. Chain of Thoughts\n",
    "print(\"Chain of Thoughts\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "xot_template = PromptTemplate(\n",
    "        template=\"\"\"Think through this step-by-step:\n",
    "1. Consider who needs remote work\n",
    "2. Define eligibility criteria\n",
    "3. Set communication requirements\n",
    "4. Establish work hours and availability\n",
    "5. Specify equipment and security needs\n",
    "\n",
    "Problem: {problem}\n",
    "\n",
    "Work through each step to create the policy:\"\"\",\n",
    "        input_variables=[\"problem\"]\n",
    "    )\n",
    "\n",
    "xot_prompt = xot_template.format(\n",
    "\tproblem=test_problem\n",
    ")\n",
    "\n",
    "xot_result = llm.invoke(xot_prompt)\n",
    "results[\"chain-of-thoughts\"] = xot_result.content\n",
    "print(f\"Preview: {xot_result.content[:100]}...\\n\")\n",
    "\n",
    "print(\"Techniques comparison\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "for technique, response in results.items():\n",
    "\tprint(f\"\\n{technique.upper()}: \")\n",
    "\tprint(f\" Length: {len(response)} characters\")\n",
    "\tprint(f\" Has Structured: {'numbered' in response.lower() or '1. ' in response}\")\n",
    "\tprint(f\" Specificity: {'employee' in response.lower() and 'remote' in response.lower()}\")\n",
    "\n",
    "lengths = {k:len(v) for k,v in results.items()}\n",
    "most_detailed = max(lengths, key=lengths.get)\n",
    "\n",
    "print(f\"\\n Most Detailed: {most_detailed} ({lengths[most_detailed]} characters)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93485c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
