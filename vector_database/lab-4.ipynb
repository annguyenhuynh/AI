{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27d00ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from typing import List\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba339d0e",
   "metadata": {},
   "source": [
    "#### Understanding embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d974159",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: forgot my password\n",
      "\n",
      "Results (score > 0.3 = relevant): \n",
      "âœ… [0.56] Password recovery: Use the 'Reset Password' link on login page\n",
      "  [0.07] Vacation policy: Request time off 2 weeks in advance\n",
      "âœ… [0.31] Account security: Enable two-factor authentication\n",
      "âœ… [0.60] Login help: contact IT if you cannot access your account\n",
      "\n",
      "ðŸ’¡ Notice: Found 'Password recovery' and 'Login help'\n",
      " Even though query didn't contain those exact words\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "query = \"forgot my password\"\n",
    "\n",
    "docs = [\n",
    "    \"Password recovery: Use the 'Reset Password' link on login page\",\n",
    "    \"Vacation policy: Request time off 2 weeks in advance\",\n",
    "    \"Account security: Enable two-factor authentication\",\n",
    "    \"Login help: contact IT if you cannot access your account\" \n",
    "]\n",
    "\n",
    "# Convert query and docs into embeddings\n",
    "query_emb = model.encode(query)\n",
    "doc_emb = model.encode(docs)\n",
    "\n",
    "scores = util.cos_sim(query_emb,doc_emb)[0]\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"Results (score > 0.3 = relevant): \")\n",
    "\n",
    "for doc, score in zip(docs, scores):\n",
    "    marker = \"âœ…\" if score > 0.3 else \" \"\n",
    "    print(f\"{marker} [{score:.2f}] {doc}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Notice: Found 'Password recovery' and 'Login help'\")\n",
    "print(\" Even though query didn't contain those exact words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376fdbe3",
   "metadata": {},
   "source": [
    "#### 2. Document Processing with Smart Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fa2c91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "Original document length: 1599 characters\n",
      "\n",
      "Chunking results:\n",
      ". Created 5 chunks\n",
      ". Chunk size: ~500 characters\n",
      ". Overlap: 100 characters\n",
      "\n",
      "Chunk 1 (496 chars):\n",
      "----------------------------------------\n",
      "TechDocs Employee Handbook\n",
      "\n",
      "    Chapter 1: Remote Work Policy\n",
      "\n",
      "    Our company embraces flexible work arrangements to support work-life balance.\n",
      "    Employees are permitted to work remotely up to 3 da...\n",
      "Chunk 2 (499 chars):\n",
      "----------------------------------------\n",
      "expectations.\n",
      "    Remote work requires manager approval and must not impact team collaboration or\n",
      "    customer service quality.\n",
      "\n",
      "    To work remotely, employees must have a suitable home office setup ...\n",
      "Chunk 3 (492 chars):\n",
      "----------------------------------------\n",
      "provides a one-time stipend of $500 for home office setup. VPN access is mandatory\n",
      "    for accessing company systems remotely.\n",
      "\n",
      "    Chapter 2: Communication Guidelines\n",
      "\n",
      "    Effective communication is ...\n",
      "----------------------------------------\n",
      "Found overlap: expectations.\n",
      "    Remote work requires manager app...\n",
      "Context preservered between chunks\n"
     ]
    }
   ],
   "source": [
    "from torch import long\n",
    "\n",
    "\n",
    "print(\"=\"*55)\n",
    "\n",
    "long_document = \"\"\"\n",
    "TechDocs Employee Handbook\n",
    "\n",
    "    Chapter 1: Remote Work Policy\n",
    "\n",
    "    Our company embraces flexible work arrangements to support work-life balance.\n",
    "    Employees are permitted to work remotely up to 3 days per week, provided they\n",
    "    maintain regular communication with their team and meet all performance expectations.\n",
    "    Remote work requires manager approval and must not impact team collaboration or\n",
    "    customer service quality.\n",
    "\n",
    "    To work remotely, employees must have a suitable home office setup with reliable\n",
    "    internet connection, appropriate workspace, and necessary equipment. The company\n",
    "    provides a one-time stipend of $500 for home office setup. VPN access is mandatory\n",
    "    for accessing company systems remotely.\n",
    "\n",
    "    Chapter 2: Communication Guidelines\n",
    "\n",
    "    Effective communication is essential for remote work success. All employees must\n",
    "    be available during core hours (10 AM - 3 PM in their local timezone) for meetings\n",
    "    and collaboration. Slack is our primary communication tool, with response times\n",
    "    expected within 2 hours during work hours.\n",
    "\n",
    "    Video calls are encouraged for team meetings to maintain personal connections.\n",
    "    Camera use is optional but recommended. All meetings should have clear agendas\n",
    "    and action items documented in our project management system.\n",
    "\n",
    "    Chapter 3: Performance Management\n",
    "\n",
    "    Remote work does not change performance expectations. Managers will evaluate\n",
    "    employees based on deliverables, quality of work, and contribution to team goals\n",
    "    rather than hours logged. Regular 1-on-1 meetings should continue virtually.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Original document length: {len(long_document)} characters\")\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    separators=[\" \"]\n",
    ")\n",
    "\n",
    "# Split the document\n",
    "chunks = splitter.split_text(long_document)\n",
    "\n",
    "print(f\"\\nChunking results:\")\n",
    "print(f\". Created {len(chunks)} chunks\")\n",
    "print(f\". Chunk size: ~500 characters\")\n",
    "print(f\". Overlap: 100 characters\\n\")\n",
    "\n",
    "for i, chunk in enumerate(chunks[:3],1):\n",
    "    print(f\"Chunk {i} ({len(chunk)} chars):\")\n",
    "    print(\"-\"*40)\n",
    "    print(chunk[:200] + \"...\" if len(chunk) > 200 else chunk)\n",
    "\n",
    "\n",
    "# Analyze overlaps\n",
    "if len(chunk) > 1:\n",
    "    overlap_start = chunks[1][:100]\n",
    "    print(\"-\"*40)\n",
    "    print(f\"Found overlap: {overlap_start[:50]}...\")\n",
    "    print(\"Context preservered between chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00191786",
   "metadata": {},
   "source": [
    "#### 3. Building Vectorstore with ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2b2197d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Model loaded\n",
      "Created 5 chunks\n",
      "Vector store created with 5 vectors\n",
      "\n",
      " Query: Can I work from home?\n",
      "Best match: Remote Work Policy: Employees can work from home up to 3 days per week.\n",
      "        VPN access required....\n",
      "    Source: handbook_section_1\n",
      "\n",
      " Query: What's the dress code for Friday?\n",
      "Best match: Dress Code: Business casual Monday-Thursday. Casual Fridays allow jeans. Client meetings require bus...\n",
      "    Source: handbook_section_5\n",
      "\n",
      " Query: How many vaction days do I get?\n",
      "Best match: Vacation Policy: 15 days PTO for first year, 20 days after 2 years.\n",
      "        Sick leave separate - 10...\n",
      "    Source: handbook_section_3\n"
     ]
    }
   ],
   "source": [
    "from sympy import per\n",
    "\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"all-MiniLM-L6-v2\",\n",
    "    model_kwargs={'device':'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "\n",
    "print(\"Embedding Model loaded\")\n",
    "\n",
    "document_text = [\"\"\"Remote Work Policy: Employees can work from home up to 3 days per week.\n",
    "        VPN access required. Core hours 10 AM - 3 PM local time. Manager approval needed.\"\"\",\n",
    "\n",
    "        \"\"\"Office Benefits: Free lunch on Tuesdays and Thursdays. Gym membership reimbursement\n",
    "        up to $50/month. Annual learning budget of $2000 for courses and conferences.\"\"\",\n",
    "\n",
    "        \"\"\"Vacation Policy: 15 days PTO for first year, 20 days after 2 years.\n",
    "        Sick leave separate - 10 days per year. Holidays follow local calendar.\"\"\",\n",
    "\n",
    "        \"\"\"Security Guidelines: Two-factor authentication required for all accounts.Password changes every 90 days. No sharing of credentials. Report incidents immediately\"\"\",\n",
    "        \n",
    "        \"\"\"Dress Code: Business casual Monday-Thursday. Casual Fridays allow jeans. Client meetings require business formal. Work from home has no dress code requirements.\"\"\"]\n",
    "\n",
    "\n",
    "for i, text in enumerate(document_text):\n",
    "    doc = Document(\n",
    "        page_content=text,\n",
    "        metadata={\n",
    "            \"source\": f\"handbook_section_{i+1}\",\n",
    "            \"type\": \"policy\",\n",
    "            \"id\": 1,   \n",
    "        }\n",
    "    )\n",
    "    document.append(doc)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "splits = text_splitter.split_documents(document)\n",
    "print(f\"Created {len(splits)} chunks\")\n",
    "\n",
    "with tempfile.TemporaryDirectory() as temp_dir:\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=splits,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=temp_dir,\n",
    "        collection_name=\"techdocs\"\n",
    "    )\n",
    "    print(f\"Vector store created with {vectorstore._collection.count()} vectors\")\n",
    "\n",
    "    test_queries = [\n",
    "        \"Can I work from home?\",\n",
    "        \"What's the dress code for Friday?\",\n",
    "        \"How many vaction days do I get?\"\n",
    "    ]\n",
    "\n",
    "    for query in test_queries:\n",
    "        print(f\"\\n Query: {query}\")\n",
    "        results = vectorstore.similarity_search(query, k=1)\n",
    "        if results:\n",
    "            print(f\"Best match: {results[0].page_content[:100]}...\")\n",
    "            print(f\"    Source: {results[0].metadata.get('source','unknown')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea44ad0",
   "metadata": {},
   "source": [
    "#### 4. Semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26c8185f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 12 documents into vector store...\n",
      "ðŸ”ŽSearching for: 'work from home policy'\n",
      "    Returning top 3 results\n",
      "----------------------------------------\n",
      "\n",
      "Search Results:\n",
      "\n",
      "1.Remote work policy allows employees to work from home up to 3 days per week with manager approval.\n",
      "\n",
      "2.Work hours are flexible but core hours 10 AM to 3 PM are required.\n",
      "\n",
      "3.Health insurance covers employee and dependents with company paying 80% of premiums.\n",
      "Filtered search (search(threshold > 1.3):\n",
      "\n",
      "Score: 0.707\n",
      "    Remote work policy allows employees to work from home up to 3 days per week with manager approval....\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import enet_path\n",
    "\n",
    "\n",
    "knowledge_base = [\n",
    "        \"Remote work policy allows employees to work from home up to 3 days per week with manager approval.\",\n",
    "        \"Dress code is business casual Monday-Thursday. Jeans are permitted on Fridays only.\",\n",
    "        \"Annual performance reviews happen in December with mid-year check-ins in June.\",\n",
    "        \"Health insurance covers employee and dependents with company paying 80% of premiums.\",\n",
    "        \"401k retirement plan includes company match up to 6% of salary.\",\n",
    "        \"Vacation policy provides 15 days PTO first year, increasing to 20 days after 2 years.\",\n",
    "        \"Sick leave is separate from vacation with 10 days allocated annually.\",\n",
    "        \"Training budget of $2000 per employee for professional development courses.\",\n",
    "        \"Office provides free lunch on Tuesdays and Thursdays for all employees.\",\n",
    "        \"Parking is free for all employees in the company garage.\",\n",
    "        \"Work hours are flexible but core hours 10 AM to 3 PM are required.\",\n",
    "        \"Security policy requires password changes every 90 days and two-factor authentication.\"\n",
    "    ]\n",
    "\n",
    "documents = [Document(page_content=text, metadata={\"id\":1})\n",
    "             for i, text in enumerate(knowledge_base)]\n",
    "\n",
    "print(f\"Loading {len(documents)} documents into vector store...\")\n",
    "\n",
    "# Create vector store\n",
    "with tempfile.TemporaryDirectory() as temp_dir:\n",
    "    vectorstore=Chroma.from_documents(\n",
    "        documents=documents,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=temp_dir\n",
    "    )\n",
    "    \n",
    "    search_query = \"work from home policy\"\n",
    "    \n",
    "    # Number of results\n",
    "    k=3\n",
    "\n",
    "    print(f\"ðŸ”ŽSearching for: '{search_query}'\")\n",
    "    print(f\"    Returning top {k} results\")\n",
    "    print(\"-\"*40)\n",
    "\n",
    "    results=vectorstore.similarity_search(search_query,k=k)\n",
    "\n",
    "    print(\"\\nSearch Results:\")\n",
    "    for i, doc in enumerate(results,1):\n",
    "        print(f\"\\n{i}.{doc.page_content}\")\n",
    "\n",
    "    score_threshold = 1.3\n",
    "    print(f\"Filtered search (search(threshold > {score_threshold}):\")\n",
    "\n",
    "    results_with_score=vectorstore.similarity_search_with_score(\n",
    "        search_query,\n",
    "        k=5\n",
    "    )   \n",
    "\n",
    "    relevant_results = [(doc, score) for doc, score in results_with_score \n",
    "                        if score <= score_threshold]\n",
    "\n",
    "    if relevant_results:\n",
    "        for doc, score in relevant_results[:3]:\n",
    "            print(f\"\\nScore: {score:.3f}\")\n",
    "            print(f\"    {doc.page_content[:100]}...\")\n",
    "\n",
    "    else:\n",
    "        print(\"No results above threshold\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7798be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ 'Can I bring my dog to work?' -> Found: dress code\n",
      "âœ… 'How many days off?' -> Found: vacation\n",
      "âœ… 'retirement savings' -> Found: 401k\n"
     ]
    }
   ],
   "source": [
    "# Advanced search demonstrations\n",
    "test_searches = [\n",
    "    (\"Can I bring my dog to work?\", \"dress code\"),\n",
    "    (\"How many days off?\", \"vacation\"),\n",
    "    (\"retirement savings\", \"401k\")\n",
    "]\n",
    "\n",
    "for query, expected_topic in test_searches:\n",
    "    results_1=vectorstore.similarity_search(query,k=1)\n",
    "    found_topic=expected_topic.lower() in results_1[0].page_content.lower()\n",
    "    status=\"âœ…\" if found_topic else \"âŒ\"\n",
    "    print(f\"{status} '{query}' -> Found: {expected_topic}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
